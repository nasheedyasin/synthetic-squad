{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fj383jqAbD6",
        "outputId": "2457dfd7-ac3d-4cf3-8ea0-ac4825643a5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/NLP Project/src')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GGO3L43xAlEF",
        "outputId": "755a486d-d403-4d58-ff9d-f172d2baeede"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/NLP Project/src'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_tfidf import *\n",
        "from transformers import AutoModel\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def load_model(model_path, labels2id, test_features, model_name=\"roberta-base\"):\n",
        "  pretrained_model = AutoModel.from_pretrained(model_name)\n",
        "  concat_model = BERT_TFIDF_Classifier(pretrained_model, num_classes=len(labels2id), tfidf_size=test_features.shape[1])\n",
        "  concat_model = nn.DataParallel(concat_model)\n",
        "  \n",
        "  concat_model.load_state_dict(torch.load(model_path))\n",
        "  return concat_model\n",
        "\n",
        "def plot_cm(preds,true_label):\n",
        "  cm = confusion_matrix(true_label, preds)\n",
        "\n",
        "  # plot the confusion matrix\n",
        "  classes = [\"Human\", \"Machine\"]\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in np.ndindex(cm.shape):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "  plt.xlabel('Predicted Label')\n",
        "  plt.ylabel('True Label')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ezrc2mbQEJbY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('../nlp-data/liwc_pos_dep_tr.csv')\n",
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "\n",
        "labels2id = {l: i for i, l in enumerate(train_df['alg'].unique())}\n",
        "\n",
        "vectorizer = joblib.load(\"../New/models/roberta_base_pos_dep_liwc/vectorizer.pkl\")\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "model = load_model(\"../New/models_state/roberta_base_pos_dep_liwc/checkpoint_epoch=4-val_loss=0.16928044552332722.ckpt\",labels2id,test_features)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uGA0WJYEdnU",
        "outputId": "ea37d42b-2f96-47c6-83b9-5b2a5849788a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.99      0.98      0.99       107\n",
            "        fair       0.98      0.95      0.96       111\n",
            "         gpt       1.00      1.00      1.00       106\n",
            "        gpt2       0.96      0.96      0.96       107\n",
            "        gpt3       0.98      0.73      0.84       143\n",
            "      grover       0.93      0.98      0.96       102\n",
            "       human       0.99      0.97      0.98       216\n",
            " instructgpt       0.63      0.99      0.77        68\n",
            "        pplm       0.99      1.00      1.00       105\n",
            "         xlm       0.99      1.00      1.00       106\n",
            "       xlnet       1.00      0.99      1.00       108\n",
            "\n",
            "    accuracy                           0.95      1279\n",
            "   macro avg       0.95      0.96      0.95      1279\n",
            "weighted avg       0.96      0.95      0.95      1279\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      0.97      0.98       216\n",
            "     machine       0.99      1.00      1.00      1063\n",
            "\n",
            "    accuracy                           0.99      1279\n",
            "   macro avg       0.99      0.98      0.99      1279\n",
            "weighted avg       0.99      0.99      0.99      1279\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         1\n",
            "         gpt       0.00      0.00      0.00        63\n",
            "        gpt2       0.00      0.00      0.00         1\n",
            "        gpt3       0.95      0.68      0.79      1245\n",
            "      grover       0.00      0.00      0.00        30\n",
            "       human       0.37      1.00      0.54       326\n",
            " instructgpt       0.56      0.50      0.53       971\n",
            "       xlnet       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.63      2644\n",
            "   macro avg       0.23      0.27      0.23      2644\n",
            "weighted avg       0.70      0.63      0.63      2644\n",
            "\n",
            "-------------------REDDIT DATA-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      0.97      0.98       216\n",
            "     machine       0.99      1.00      1.00      1063\n",
            "\n",
            "    accuracy                           0.99      1279\n",
            "   macro avg       0.99      0.98      0.99      1279\n",
            "weighted avg       0.99      0.99      0.99      1279\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CTRL"
      ],
      "metadata": {
        "id": "tlKEoDT6HHdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['ctrl','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzuDTXy0F2_-",
        "outputId": "b756a615-bc13-42f9-a3fe-856fe2b43f7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.99      1.00      1.00       105\n",
            "        fair       0.00      0.00      0.00         2\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.49      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.98       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. FAIR"
      ],
      "metadata": {
        "id": "UwHL8b2ZgHHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['fair','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr7s8EiN-5vo",
        "outputId": "74c2c711-d5c4-4239-fcbf-82ff4a5bfabe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.98      0.99      0.99       106\n",
            "         gpt       0.00      0.00      0.00         1\n",
            "        gpt2       0.00      0.00      0.00         2\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.98      1.00      0.99       209\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.39      0.40      0.40       320\n",
            "weighted avg       0.97      0.98      0.97       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.98      1.00      0.99       209\n",
            "     machine       1.00      0.96      0.98       111\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.98      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. GROVER"
      ],
      "metadata": {
        "id": "0YgpheY-gJbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['grover','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j7-t0uB-6DX",
        "outputId": "859e9b8d-2277-4392-9417-816511789953"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         1\n",
            "        fair       0.00      0.00      0.00         2\n",
            "      grover       0.94      0.98      0.96       103\n",
            "       human       0.99      0.98      0.98       214\n",
            "\n",
            "    accuracy                           0.97       320\n",
            "   macro avg       0.48      0.49      0.49       320\n",
            "weighted avg       0.96      0.97      0.97       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      0.98      0.98       214\n",
            "     machine       0.96      0.97      0.97       106\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.97      0.98      0.98       320\n",
            "weighted avg       0.98      0.98      0.98       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. GPT2"
      ],
      "metadata": {
        "id": "-gMP7I5dgMfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt2','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg7OXnvQ-698",
        "outputId": "c0a2cc9e-e045-4213-f20c-c788333ed3b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         5\n",
            "        gpt2       0.95      1.00      0.98       102\n",
            "      grover       0.00      0.00      0.00         3\n",
            "       human       0.98      1.00      0.99       209\n",
            "       xlnet       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.97       320\n",
            "   macro avg       0.39      0.40      0.39       320\n",
            "weighted avg       0.94      0.97      0.96       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.98      1.00      0.99       209\n",
            "     machine       1.00      0.96      0.98       111\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.98      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. GPT3"
      ],
      "metadata": {
        "id": "DMo3qjPVgPG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt3','human'])]\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "reddit_df = reddit_df[reddit_df['alg'].isin(['gpt3','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6x9whFw-7Wj",
        "outputId": "ca4959f3-0ed5-4c73-99eb-1c532ce96cc7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "        gpt2       0.00      0.00      0.00         1\n",
            "        gpt3       0.98      1.00      0.99       105\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            " instructgpt       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.33      0.33      0.33       320\n",
            "weighted avg       0.97      0.98      0.98       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         2\n",
            "         gpt       0.00      0.00      0.00        68\n",
            "        gpt3       0.95      0.98      0.97       862\n",
            "      grover       0.00      0.00      0.00        28\n",
            "       human       0.37      1.00      0.54       331\n",
            " instructgpt       0.00      0.00      0.00       471\n",
            "       xlnet       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.66      1768\n",
            "   macro avg       0.19      0.28      0.22      1768\n",
            "weighted avg       0.54      0.66      0.57      1768\n",
            "\n",
            "-------------------REDDIT DATA-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. InstructGPT"
      ],
      "metadata": {
        "id": "bKKyp-2ggQhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['instructgpt','human'])]\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "reddit_df = reddit_df[reddit_df['alg'].isin(['instructgpt','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz8M3ytX-7q8",
        "outputId": "c33716d1-8d27-4f90-9c1d-6a20505a645e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "        gpt3       0.00      0.00      0.00        37\n",
            "      grover       0.00      0.00      0.00         1\n",
            "       human       0.99      1.00      0.99       212\n",
            " instructgpt       0.64      1.00      0.78        68\n",
            "\n",
            "    accuracy                           0.87       319\n",
            "   macro avg       0.33      0.40      0.35       319\n",
            "weighted avg       0.80      0.87      0.83       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       212\n",
            "     machine       0.99      0.98      0.99       107\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         2\n",
            "         gpt       0.00      0.00      0.00        65\n",
            "        gpt2       0.00      0.00      0.00         1\n",
            "        gpt3       0.00      0.00      0.00       404\n",
            "      grover       0.00      0.00      0.00        31\n",
            "       human       0.37      1.00      0.54       323\n",
            " instructgpt       0.56      0.53      0.54       927\n",
            "       xlnet       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.46      1760\n",
            "   macro avg       0.12      0.19      0.13      1760\n",
            "weighted avg       0.36      0.46      0.38      1760\n",
            "\n",
            "-------------------REDDIT DATA-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       212\n",
            "     machine       0.99      0.98      0.99       107\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. GPT"
      ],
      "metadata": {
        "id": "woOwsGIbgToY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y0VL1s2-8C9",
        "outputId": "bebe1ddc-2a99-4b30-c450-505672e775ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "         gpt       1.00      1.00      1.00       106\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.50      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.99       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. PPLM"
      ],
      "metadata": {
        "id": "X4QxptuwgVkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['pplm','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB2WldWb-8Zy",
        "outputId": "5196eae3-b0c7-449f-ce60-5b8cd257e011"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "        pplm       1.00      1.00      1.00       106\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.50      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.99       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. XLNET"
      ],
      "metadata": {
        "id": "UfL1dnB3gZoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['xlnet','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA1blqYR-8p9",
        "outputId": "002ed3e9-87f0-4a01-ab88-c10adb15bc50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         1\n",
            "       human       0.99      1.00      1.00       211\n",
            "       xlnet       1.00      1.00      1.00       107\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.50      0.50      0.50       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      1.00       211\n",
            "     machine       1.00      0.98      0.99       109\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       1.00      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. XLM"
      ],
      "metadata": {
        "id": "oz_OM8XrgbzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['xlm','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"])\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, numerical_fields=[\"semantic_coherence\", \"Analytic\", \"WPS\", \"article\", \"Period\"], batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ93C-B_-9aC",
        "outputId": "4ca0acef-99f7-468b-d955-e4e6ac9d46bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "         xlm       1.00      1.00      1.00       107\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.50      0.50      0.50       320\n",
            "weighted avg       0.98      0.99      0.99       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBkftaShJcGx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS Models"
      ],
      "metadata": {
        "id": "UNfmXzWCK1Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('../nlp-data/liwc_pos_dep_tr.csv')\n",
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "\n",
        "labels2id = {l: i for i, l in enumerate(train_df['alg'].unique())}\n",
        "\n",
        "vectorizer = joblib.load(\"../New/models/roberta_base_pos/vectorizer.pkl\")\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "model = load_model(\"../New/models_state/roberta_base_pos/checkpoint_epoch=3-val_loss=0.ckpt\",labels2id,test_features)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bv_gssK2LIXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CTRL"
      ],
      "metadata": {
        "id": "rSCypJEcL0Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['ctrl','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b756a615-bc13-42f9-a3fe-856fe2b43f7c",
        "id": "SvZ5QqJbL0Rl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.99      1.00      1.00       105\n",
            "        fair       0.00      0.00      0.00         2\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.49      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.98       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. FAIR"
      ],
      "metadata": {
        "id": "LqFArMtoL0Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['fair','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c2c711-d5c4-4239-fcbf-82ff4a5bfabe",
        "id": "l0dlfLfvL0Rm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.98      0.99      0.99       106\n",
            "         gpt       0.00      0.00      0.00         1\n",
            "        gpt2       0.00      0.00      0.00         2\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.98      1.00      0.99       209\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.39      0.40      0.40       320\n",
            "weighted avg       0.97      0.98      0.97       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.98      1.00      0.99       209\n",
            "     machine       1.00      0.96      0.98       111\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.98      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. GROVER"
      ],
      "metadata": {
        "id": "eWiK3p-4L0Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['grover','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859e9b8d-2277-4392-9417-816511789953",
        "id": "aub-ueXjL0Rm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         1\n",
            "        fair       0.00      0.00      0.00         2\n",
            "      grover       0.94      0.98      0.96       103\n",
            "       human       0.99      0.98      0.98       214\n",
            "\n",
            "    accuracy                           0.97       320\n",
            "   macro avg       0.48      0.49      0.49       320\n",
            "weighted avg       0.96      0.97      0.97       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      0.98      0.98       214\n",
            "     machine       0.96      0.97      0.97       106\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.97      0.98      0.98       320\n",
            "weighted avg       0.98      0.98      0.98       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. GPT2"
      ],
      "metadata": {
        "id": "rguY8S0FL0Rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt2','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a2cc9e-e045-4213-f20c-c788333ed3b1",
        "id": "XSHvthTaL0Rn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         5\n",
            "        gpt2       0.95      1.00      0.98       102\n",
            "      grover       0.00      0.00      0.00         3\n",
            "       human       0.98      1.00      0.99       209\n",
            "       xlnet       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.97       320\n",
            "   macro avg       0.39      0.40      0.39       320\n",
            "weighted avg       0.94      0.97      0.96       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.98      1.00      0.99       209\n",
            "     machine       1.00      0.96      0.98       111\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.98      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. GPT3"
      ],
      "metadata": {
        "id": "zeapE69eL0Rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt3','human'])]\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "reddit_df = reddit_df[reddit_df['alg'].isin(['gpt3','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4959f3-0ed5-4c73-99eb-1c532ce96cc7",
        "id": "7xfRIw_sL0Rn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "        gpt2       0.00      0.00      0.00         1\n",
            "        gpt3       0.98      1.00      0.99       105\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            " instructgpt       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.33      0.33      0.33       320\n",
            "weighted avg       0.97      0.98      0.98       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         2\n",
            "         gpt       0.00      0.00      0.00        68\n",
            "        gpt3       0.95      0.98      0.97       862\n",
            "      grover       0.00      0.00      0.00        28\n",
            "       human       0.37      1.00      0.54       331\n",
            " instructgpt       0.00      0.00      0.00       471\n",
            "       xlnet       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.66      1768\n",
            "   macro avg       0.19      0.28      0.22      1768\n",
            "weighted avg       0.54      0.66      0.57      1768\n",
            "\n",
            "-------------------REDDIT DATA-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. InstructGPT"
      ],
      "metadata": {
        "id": "qsjgjsk1L0Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['instructgpt','human'])]\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "reddit_df = reddit_df[reddit_df['alg'].isin(['instructgpt','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33716d1-8d27-4f90-9c1d-6a20505a645e",
        "id": "bErfOb-aL0Ro"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "        gpt3       0.00      0.00      0.00        37\n",
            "      grover       0.00      0.00      0.00         1\n",
            "       human       0.99      1.00      0.99       212\n",
            " instructgpt       0.64      1.00      0.78        68\n",
            "\n",
            "    accuracy                           0.87       319\n",
            "   macro avg       0.33      0.40      0.35       319\n",
            "weighted avg       0.80      0.87      0.83       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       212\n",
            "     machine       0.99      0.98      0.99       107\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         2\n",
            "         gpt       0.00      0.00      0.00        65\n",
            "        gpt2       0.00      0.00      0.00         1\n",
            "        gpt3       0.00      0.00      0.00       404\n",
            "      grover       0.00      0.00      0.00        31\n",
            "       human       0.37      1.00      0.54       323\n",
            " instructgpt       0.56      0.53      0.54       927\n",
            "       xlnet       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.46      1760\n",
            "   macro avg       0.12      0.19      0.13      1760\n",
            "weighted avg       0.36      0.46      0.38      1760\n",
            "\n",
            "-------------------REDDIT DATA-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       212\n",
            "     machine       0.99      0.98      0.99       107\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. GPT"
      ],
      "metadata": {
        "id": "wObGWuzVL0Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebe1ddc-2a99-4b30-c450-505672e775ab",
        "id": "5SKxdzV-L0Ro"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "         gpt       1.00      1.00      1.00       106\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.50      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.99       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. PPLM"
      ],
      "metadata": {
        "id": "1fGDoI2dL0Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['pplm','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5196eae3-b0c7-449f-ce60-5b8cd257e011",
        "id": "dFQ0pXS1L0Ro"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "        pplm       1.00      1.00      1.00       106\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.50      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.99       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. XLNET"
      ],
      "metadata": {
        "id": "BM63DM86L0Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['xlnet','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002ed3e9-87f0-4a01-ab88-c10adb15bc50",
        "id": "wB4qfhjAL0Rp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         1\n",
            "       human       0.99      1.00      1.00       211\n",
            "       xlnet       1.00      1.00      1.00       107\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.50      0.50      0.50       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      1.00       211\n",
            "     machine       1.00      0.98      0.99       109\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       1.00      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. XLM"
      ],
      "metadata": {
        "id": "qyQ1iO56L0Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['xlm','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca0acef-99f7-468b-d955-e4e6ac9d46bb",
        "id": "tvoecxBWL0Rp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "         xlm       1.00      1.00      1.00       107\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.50      0.50      0.50       320\n",
            "weighted avg       0.98      0.99      0.99       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS Dependency Tfidf +  ROBERTA"
      ],
      "metadata": {
        "id": "BIeusavzOGyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('../nlp-data/liwc_pos_dep_tr.csv')\n",
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "\n",
        "labels2id = {l: i for i, l in enumerate(train_df['alg'].unique())}\n",
        "\n",
        "vectorizer = joblib.load(\"../New/models/roberta_base_pos_dep/vectorizer.pkl\")\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "model = load_model(\"../New/models_state/roberta_base_pos_dep/checkpoint_epoch=2-val_loss=0.21201472314229855.ckpt\",labels2id,test_features)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "id": "5HGYl0kjOLWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CTRL"
      ],
      "metadata": {
        "id": "QmWsL8eYOpKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['ctrl','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b756a615-bc13-42f9-a3fe-856fe2b43f7c",
        "id": "m73wyrWjOpKx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.99      1.00      1.00       105\n",
            "        fair       0.00      0.00      0.00         2\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.49      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.98       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. FAIR"
      ],
      "metadata": {
        "id": "VomyVUMkOpKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['fair','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c2c711-d5c4-4239-fcbf-82ff4a5bfabe",
        "id": "FmEyyz9yOpKx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.98      0.99      0.99       106\n",
            "         gpt       0.00      0.00      0.00         1\n",
            "        gpt2       0.00      0.00      0.00         2\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.98      1.00      0.99       209\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.39      0.40      0.40       320\n",
            "weighted avg       0.97      0.98      0.97       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.98      1.00      0.99       209\n",
            "     machine       1.00      0.96      0.98       111\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.98      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. GROVER"
      ],
      "metadata": {
        "id": "c0YvmCT4OpKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['grover','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859e9b8d-2277-4392-9417-816511789953",
        "id": "W7aLVqKAOpKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         1\n",
            "        fair       0.00      0.00      0.00         2\n",
            "      grover       0.94      0.98      0.96       103\n",
            "       human       0.99      0.98      0.98       214\n",
            "\n",
            "    accuracy                           0.97       320\n",
            "   macro avg       0.48      0.49      0.49       320\n",
            "weighted avg       0.96      0.97      0.97       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      0.98      0.98       214\n",
            "     machine       0.96      0.97      0.97       106\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.97      0.98      0.98       320\n",
            "weighted avg       0.98      0.98      0.98       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. GPT2"
      ],
      "metadata": {
        "id": "ve6dpBErOpKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt2','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a2cc9e-e045-4213-f20c-c788333ed3b1",
        "id": "j0AsqtAVOpKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         5\n",
            "        gpt2       0.95      1.00      0.98       102\n",
            "      grover       0.00      0.00      0.00         3\n",
            "       human       0.98      1.00      0.99       209\n",
            "       xlnet       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.97       320\n",
            "   macro avg       0.39      0.40      0.39       320\n",
            "weighted avg       0.94      0.97      0.96       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.98      1.00      0.99       209\n",
            "     machine       1.00      0.96      0.98       111\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.98      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. GPT3"
      ],
      "metadata": {
        "id": "yz6YxR4JOpKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt3','human'])]\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "reddit_df = reddit_df[reddit_df['alg'].isin(['gpt3','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4959f3-0ed5-4c73-99eb-1c532ce96cc7",
        "id": "FXErAoqyOpKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "        gpt2       0.00      0.00      0.00         1\n",
            "        gpt3       0.98      1.00      0.99       105\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            " instructgpt       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98       320\n",
            "   macro avg       0.33      0.33      0.33       320\n",
            "weighted avg       0.97      0.98      0.98       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         2\n",
            "         gpt       0.00      0.00      0.00        68\n",
            "        gpt3       0.95      0.98      0.97       862\n",
            "      grover       0.00      0.00      0.00        28\n",
            "       human       0.37      1.00      0.54       331\n",
            " instructgpt       0.00      0.00      0.00       471\n",
            "       xlnet       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.66      1768\n",
            "   macro avg       0.19      0.28      0.22      1768\n",
            "weighted avg       0.54      0.66      0.57      1768\n",
            "\n",
            "-------------------REDDIT DATA-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. InstructGPT"
      ],
      "metadata": {
        "id": "J0HDU9siOpKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['instructgpt','human'])]\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "reddit_df = reddit_df[reddit_df['alg'].isin(['instructgpt','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n",
        "\n",
        "# For Reddit\n",
        "preds, true_label = evaluate_test(model, reddit_dataloader, labels2id, reddit_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------REDDIT DATA-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33716d1-8d27-4f90-9c1d-6a20505a645e",
        "id": "Iecf8iK0OpKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "        gpt3       0.00      0.00      0.00        37\n",
            "      grover       0.00      0.00      0.00         1\n",
            "       human       0.99      1.00      0.99       212\n",
            " instructgpt       0.64      1.00      0.78        68\n",
            "\n",
            "    accuracy                           0.87       319\n",
            "   macro avg       0.33      0.40      0.35       319\n",
            "weighted avg       0.80      0.87      0.83       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       212\n",
            "     machine       0.99      0.98      0.99       107\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ctrl       0.00      0.00      0.00         2\n",
            "         gpt       0.00      0.00      0.00        65\n",
            "        gpt2       0.00      0.00      0.00         1\n",
            "        gpt3       0.00      0.00      0.00       404\n",
            "      grover       0.00      0.00      0.00        31\n",
            "       human       0.37      1.00      0.54       323\n",
            " instructgpt       0.56      0.53      0.54       927\n",
            "       xlnet       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.46      1760\n",
            "   macro avg       0.12      0.19      0.13      1760\n",
            "weighted avg       0.36      0.46      0.38      1760\n",
            "\n",
            "-------------------REDDIT DATA-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       212\n",
            "     machine       0.99      0.98      0.99       107\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. GPT"
      ],
      "metadata": {
        "id": "T4RAd7GAOpKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "reddit_df = pd.read_csv('../nlp-data/liwc_pos_dep_reddit.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['gpt','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebe1ddc-2a99-4b30-c450-505672e775ab",
        "id": "HY1DjirAOpKz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "         gpt       1.00      1.00      1.00       106\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.50      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.99       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. PPLM"
      ],
      "metadata": {
        "id": "FQWPNwV7OpKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['pplm','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5196eae3-b0c7-449f-ce60-5b8cd257e011",
        "id": "-1royewZOpKz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "        pplm       1.00      1.00      1.00       106\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.50      0.50      0.50       319\n",
            "weighted avg       0.98      0.99      0.99       319\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       109\n",
            "\n",
            "    accuracy                           0.99       319\n",
            "   macro avg       0.99      0.99      0.99       319\n",
            "weighted avg       0.99      0.99      0.99       319\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. XLNET"
      ],
      "metadata": {
        "id": "a3GvpEcBOpKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['xlnet','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002ed3e9-87f0-4a01-ab88-c10adb15bc50",
        "id": "V0BLDKC5OpKz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         1\n",
            "       human       0.99      1.00      1.00       211\n",
            "       xlnet       1.00      1.00      1.00       107\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.50      0.50      0.50       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      1.00       211\n",
            "     machine       1.00      0.98      0.99       109\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       1.00      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. XLM"
      ],
      "metadata": {
        "id": "b70j3gqlOpKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../nlp-data/liwc_pos_dep_eval.csv')\n",
        "test_df = test_df[test_df['alg'].isin(['xlm','human'])]\n",
        "\n",
        "test_features = get_features_test(test_df, vectorizer)\n",
        "test_dataloader, reddit_dataloader = data_batcher_evaluate(test_df, reddit_df, vectorizer, labels2id, batch_size=32, model_name=\"roberta-base\")\n",
        "\n",
        "# For AA Paper\n",
        "preds, true_label = evaluate_test(model, test_dataloader, labels2id, test_df[\"alg\"])\n",
        "preds = ['machine' if item != 'human' else item for item in preds]\n",
        "true_label = true_label.replace(['fair', 'grover', 'gpt2', 'gpt3', 'instructgpt', 'gpt', 'ctrl', 'pplm', 'xlnet', 'xlm'],'machine')\n",
        "print(\"-------------------AA PAPER-----------------\")\n",
        "print(classification_report(preds,true_label))\n",
        "print()\n",
        "plot_cm(preds,true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca0acef-99f7-468b-d955-e4e6ac9d46bb",
        "id": "W2N26Ot3OpKz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/NLP Project/src/bert_tfidf.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tfidf_vector = torch.tensor(batch['tfidf_vector'], dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fair       0.00      0.00      0.00         1\n",
            "      grover       0.00      0.00      0.00         2\n",
            "       human       0.99      1.00      0.99       210\n",
            "         xlm       1.00      1.00      1.00       107\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.50      0.50      0.50       320\n",
            "weighted avg       0.98      0.99      0.99       320\n",
            "\n",
            "-------------------AA PAPER-----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       human       0.99      1.00      0.99       210\n",
            "     machine       1.00      0.97      0.99       110\n",
            "\n",
            "    accuracy                           0.99       320\n",
            "   macro avg       0.99      0.99      0.99       320\n",
            "weighted avg       0.99      0.99      0.99       320\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}